# ML System Design Doc - [RU]
## Дизайн ML системы - Машинный перевод с русского на мансийский язык (MVP, Итерация 1)

*Шаблон ML System Design Doc от телеграм-канала [Reliable ML](https://t.me/reliable_ml)*   

- Рекомендации по процессу заполнения документа (workflow) - [здесь](https://github.com/IrinaGoloshchapova/ml_system_design_doc_ru/blob/main/ML_System_Design_Doc_Workflow.md).  
- Детальный доклад о том, что такое ML System Design Doc и о том, как, когда и зачем его составлять - [тут](https://www.youtube.com/watch?v=PW9TGNr1Vqk).
    
> ## Термины и пояснения
> - Итерация - это все работы, которые совершаются до старта очередного пилота  
> - БТ - бизнес-требования 
> - EDA - Exploratory Data Analysis - исследовательский анализ данных  
> - `Product Owner`,  `Data Scientist` - роли, которые заполняют соответствующие разделы 
> - В этом шаблоне роль `Data Scientist` совмещает в себе компетенции классического `Data Scientist` с упором на исследования и `ML Engineer` & `ML Ops` роли с акцентом на продуктивизацию моделей
> - Для вашей организации распределение ролей может быть уточнено в зависимости от операционной модели 

### 1. Цели и предпосылки 
#### 1.1. Зачем идем в разработку продукта?  

- Бизнес-цель
  
    Целью проекта является создание доступного и эффективного инструмента для машинного перевода с русского языка на мансийский и обратно с использованием современных технологий машинного обучения.

- Почему станет лучше, чем сейчас, от использования ML

    Мансийский язык, как и многие другие языки коренных народов, находится под угрозой исчезновения. Машинный перевод может сыграть важную роль в сохранении этого языка, улучшении доступности информации на нем и популяризации среди новых поколений. С помощью машинного перевода можно будет переводить различные образовательные материалы, литературу и другие ресурсы с русского на мансийский, что значительно расширит доступность информации для носителей языка и повысит интерес к изучению языка.

- Что будем считать успехом итерации с точки зрения бизнеса
  - Функциональность API:
    - API должно быть развернуто и доступно для работы через REST-запросы.
    - API предоставляет перевод текста с русского на мансийский и обратно.
  - Быстродействие API:
    - Среднее время отклика: Перевод одной строки текста (длиной до 100 символов) выполняется за менее чем 1 секунду в 95% случаев.
    - Гарантированное время отклика (SLA): Время ответа API не превышает 2 секунд даже при максимальной нагрузке.
  - BLEU (Bilingual Evaluation Understudy):
    - Целевой показатель для базовой модели составляет 20–30% для первых итераций.
    - Сравнение модели с репрезентативным тестовым набором из параллельных предложений.
  - Удовлетворенность пользователей (реальные отзывы):
    - Минимум 80% положительных отзывов от тестовых пользователей на этапе пилота.
  - Пользовательский опыт (UX):
    - Время загрузки веб-интерфейса: Меньше 2 секунд.
    - Интуитивно понятный интерфейс для работы с API и перевода текста.

#### 1.2. Бизнес-требования и ограничения  

- Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями

    Веб-сервис должен предоставить интуитивно понятный интерфейс для пользователей, позволяя переводить текст в режиме онлайн с русского на мансийский и наоборот.
  
- Бизнес-ограничения
  - Ограниченный объем обучающих данных для мансийского языка.
  - Сроки на реализацию итерации: 3 месяца.
  - Ограниченный бюджет на инфраструктуру.
    
- Что мы ожидаем от конкретной итерации
  - Первая версия модели с базовым качеством перевода, оптимизированная под реальное использование.
  - Базовая версия пользовательского интерфейса (веб-сервис).
- Описание бизнес-процесса пилота, насколько это возможно - как именно мы будем использовать модель в существующем бизнес-процессе?

    Пользователи вводят текст на русском или мансийском в веб-интерфейсе и получают перевод на целевой язык. В пилоте используется базовая Seq2Seq модель, обученная на корпусе мансийского языка и развернутая через API.
  
- Что считаем успешным пилотом? Критерии успеха и возможные пути развития проекта
  - Веб-сервис успешно обрабатывает запросы в реальном времени.
  - BLEU-оценка для перевода соответствует запланированным метрикам.
  - Получены положительные отзывы от пользователей (минимум 80% удовлетворенности).

#### 1.3. Что входит в скоуп проекта/итерации, что не входит   

- На закрытие каких БТ подписываемся в данной итерации
  - Разработка и развертывание базовой модели машинного перевода для русского и мансийского языков.
  - Создание API для работы с переводчиком.
  - Подготовка минимального набора данных для обучения и тестирования модели.   
- Что не будет закрыто
  - Интеграция с внешними платформами.
  - Оптимизация модели для перевода длинных текстов.
- Описание результата с точки зрения качества кода и воспроизводимости решения
  Код будет полностью задокументирован и протестирован. Решение должно быть воспроизводимым для дальнейшего улучшения.  
- Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации)
  - Оптимизация модели для работы с большими текстовыми массивами.
  - Добавление системы логирования запросов и их обработки.
  - Внедрение переводчика в популярные онлайн-переводчики.

#### 1.4. Предпосылки решения  

- Описание всех общих предпосылок решения, используемых в системе – с обоснованием от запроса бизнеса: какие блоки данных используем, горизонт прогноза, гранулярность модели, и др.
  - Данные: используем корпус параллельных текстов на русском и мансийском языках. Это могут быть литературные произведения, учебные материалы и официальные документы. Однако, для достижения необходимого объема данных, будут предприняты дополнительные шаги:
    - Предобработка текста. На этапе подготовки данные будут очищены от ошибок, некорректных символов, дубликатов и пустых строк. Также будет проведена токенизация текста (разбиение на слова и предложения) и нормализация (приведение текста к единому виду). Эти меры необходимы для повышения качества обучающего корпуса.
    - Дополнение корпуса. Планируется расширить корпус данных с помощью парсинга открытых источников, таких как электронные библиотеки, учебные материалы, государственные сайты и официальные документы. Автоматизированный сбор данных позволит дополнить корпус новыми текстовыми парами, соответствующими тематике проекта.
  - Модель: базируемся на Seq2Seq-модели из библиотеки transformers. Seq2Seq подход предоставляет удобную архитектуру для обучения как на больших, так и на малых объемах данных. Базовые Seq2Seq модели легко настраиваются, поддерживают дообучение на специфических языках и предоставляют хорошие результаты для пар языков с разной структурой. Он поддерживает использование предобученных моделей, что позволяет сократить потребность в данных. Для базовой версии выбирается уже предобученная модель, дообученная на собранном корпусе данных. 
  - Горизонт прогноза: Перевод отдельных предложений или коротких абзацев текста.
  - Гранулярность: Уровень перевода — предложение или абзац, ориентированный на точность синтаксического и семантического соответствия.

### 2. Методология `Data Scientist`     

#### 2.1. Постановка задачи  

- С технической точки зрения задача формулируется как:
  - Построение системы машинного перевода на основе Seq2Seq-модели.
  - Разработка и развертывание REST API для перевода текстов.
  - Построение пайплайна, включающего:
    - Предобработку данных.
    - Обучение модели на парных данных (русский-мансийский).
    - Постобработку результата перевода.

#### 2.2. Блок-схема решения  
- ![Блок-схема](diagram.png)
    - Этап 0: Получение корпуса переводов
      - Цель этапа – собрать и подготовить корпус текстов на русском и мансийском языках, чтобы обучить модель машинного перевода. Дополнительный парсинг данных из официальных источников, включая: литературные произведения (на обоих языках). учебные материалы (словари, пособия, справочники), официальные документы (юридические, государственные).
    - Этап 1: Подготовка данных
      - На этом этапе происходит обработка корпуса переводов для их последующего использования в обучении, например, удаление лишних символов, ошибок, пустых строк.
    - Этап 2: Обучение модели
      - Этап направлен на создание и настройку моделей машинного перевода. Обучение проводится на нескольких архитектурах для выбора наилучшего решения. Результаты промежуточного обучения каждой модели сравниваются по ключевым метрикам: BLEU. Выбирается модель с наилучшим качеством перевода. Выбранная модель дообучается на более редких и сложных примерах, чтобы улучшить качество перевода специфических конструкций.
    - Этап 3: Создание веб-сервиса
      - Цель этапа – разработать функциональный веб-сервис для использования обученной модели перевода: REST API и UI с последующим объединением в единый продукт.
    - Этап 4: Нагрузочное тестирование
      - На этом этапе проводится тестирование веб-сервиса под различными нагрузками. Проверяются сценарии: обработка большого числа запросов одновременно, работа с текстами разных объёмов (короткие, длинные),корректность перевода при нестандартных данных (например, смешении языков).
    - Этап 5: MVP (Минимально жизнеспособный продукт)
      - Заключительный этап, на котором создаётся функциональный продукт, готовый для тестового использования:

#### 2.3. Этапы решения задачи `Data Scientist`  
#### *Этап 0 - EDA*  

1. Цель анализа <br>
EDA проводится для оценки состава, объема и качества данных, а также для выявления потенциальных проблем, которые могут повлиять на обучение модели. Используемый датасет содержит параллельные тексты на русском и мансийском языках.
2. Описание данных
Датасет: overall_80K.csv:
   - Количество строк: 81146
   - Колонки:
     - Unnamed: 0 — служебный индекс (удален на этапе предобработки).
     - source — текст на русском языке.
     - target — текст на мансийском языке.

3. Предобработка данных:
   - Удаление строк с одинаковыми текстами.
   - Токенизация и очистка текста.
   - Для русского языка необходимо дальнейшее улучшение качества данных (например, удаление записей с низким качеством).
- [Оригинальный датасет](../notebooks/EDA/overall_80K.csv)
- [Предобработанный датасет](../notebooks/EDA/overall_80K_corrected.csv)
- [Ноутбук](../notebooks/EDA/correcting_dataset.ipynb)   

#### *Этап 1 - Подготовка данных*  
1. Данные и сущности, на которых будет обучаться  модель машинного обучения  
  
| Название данных  | Есть ли данные в компании (если да, название источника/витрин) | Требуемый ресурс для получения данных (какие роли нужны) | Проверено ли качество данных (да, нет) |
| ------------- | ------------- | ------------- | ------------- |
| Параллельные тексты на русском и мансийском | Да (корпус overall_80K)  | DE/DS | + |
| Данные, полученные с помощью скрейпинга  | Нет (собраны дополнительно)  | DE/DS	 | + |
| Слова и выражения из мансийского словаря | Нет (скрейпинг словаря)  | DE/DS	 | + |
 
2. Описание данных, состав, объем и качество
   - Первичный датасет:
     - Исходный объем: 81146 строк × 3 столбца (Unnamed: 0, source, target).
     - Обработанный объем: 79958 строк × 2 столбца (source, target).
   - Проблемы:
     - Удалены строки с одинаковыми текстами на русском и мансийском языках (source == target), которые не добавляют ценности для обучения. Это сократило объем данных, но повысило их релевантность.
     - В текстах на русском языке выявлены "шумные" слова (плохая разборчивость с помощью морфологического анализатора).
   - Дополнения к выборке:
     - Скрапинг словаря (Афанасьева К.В., Собянина С.А.):
       - Добавлены дополнительные пары слов (мансийский-русский).
       - Эти данные увеличили объем корпуса и охват тематик, представленных в тексте.
    - Скрапинг материалов:
      - Увеличили количество записей, ориентированных на сложные синтаксические конструкции.
        
3. Данные и сущности, на которых будет обучаться  модель машинного обучения
   - Объем данных:
     - Несмотря на все предпринятые меры (скрейпинг, дополнение из словарей), объем данных остается ограниченным. Это связано с малым количеством текстов на мансийском языке в открытых источниках.
     - Риск: Невозможность обеспечить высокое качество перевода из-за нехватки данных

   - Качество данных:
     - В первичном корпусе значительных проблем с качеством не выявлено. Однако тексты на русском языке иногда включают шум, что может повлиять на обучение модели.

   - Неравномерность распределения данных:
     - Возможно, определенные темы и лексические структуры представлены слабо. Это может привести к ухудшению качества перевода в специфических областях.
       
       
 *Этапы 2 и далее, помимо подготовки данных.*
 
Описание техники **для каждого этапа** должно включать описание **отдельно для MVP** и **отдельно для бейзлайна**:  

- Описание формирования выборки для обучения, тестирования и валидации. Выбор репрезентативных данных для экспериментов, обучения и подготовки пилота (от бизнес-цели и репрезентативности данных с технической точки зрения) `Data Scientist`    
- Горизонт, гранулярность, частоту необходимого пересчета прогнозных моделей `Data Scientist`   
- Определение целевой переменной, согласованное с бизнесом `Data Scientist`   
- Какие метрики качества используем и почему они связаны с бизнес-результатом, обозначенным `Product Owner` в разделах `1` и `3`. Пример - WAPE <= 50% для > 80% категорий, bias ~ 0. Возможна формулировка в терминах относительно бейзлайна, количественно. Для бейзлайна могут быть свои целевые метрики, а может их вообще не быть (если это обосновано) `Data Scientist`   
- Необходимый результат этапа. Например, необходимым результатом может быть не просто достижение каких-либо метрик качества, а включение в модели определенных факторов (флаг промо для прогноза выручки, др.) `Data Scientist`    
- Какие могут быть риски и что планируем с этим делать. Например, необходимый для модели фактор (флаг промо) окажется незначимым для большинства моделей. Или для 50% моделей будет недостаточно данных для оценки `Data Scientist`    
- Верхнеуровневые принципы и обоснования для: feature engineering, подбора алгоритма решения, техники кросс-валидации, интерпретации результата (если применимо).  
- Предусмотрена ли бизнес-проверка результата этапа и как будет проводиться `Data Scientist` & `Product Owner`  
  
### 3. Подготовка пилота  
  
#### 3.1. Способ оценки пилота  
  
- Краткое описание предполагаемого дизайна и способа оценки пилота `Product Owner`, `Data Scientist` with `AB Group` 
  
#### 3.2. Что считаем успешным пилотом  
  
Формализованные в пилоте метрики оценки успешности `Product Owner`   
  
#### 3.3. Подготовка пилота  
  
- Что можем позволить себе, исходя из ожидаемых затрат на вычисления. Если исходно просчитать сложно, то описываем этап расчетов ожидаемой вычислительной сложности на эксперименте с бейзлайном. И предусматриваем уточнение параметров пилота и установку ограничений по вычислительной сложности моделей. `Data Scientist` 

### 4. Внедрение `для production систем, если требуется`    

> Заполнение раздела 4 требуется не для всех дизайн документов. В некоторых случаях результатом итерации может быть расчет каких-то значений, далее используемых в бизнес-процессе для пилота.  
  
#### 4.1. Архитектура решения   
  
- Блок схема и пояснения: сервисы, назначения, методы API `Data Scientist`  
  
#### 4.2. Описание инфраструктуры и масштабируемости 
  
- Какая инфраструктура выбрана и почему `Data Scientist` 
- Плюсы и минусы выбора `Data Scientist` 
- Почему финальный выбор лучше других альтернатив `Data Scientist` 
  
#### 4.3. Требования к работе системы  
  
- SLA, пропускная способность и задержка `Data Scientist`  
  
#### 4.4. Безопасность системы  
  
- Потенциальная уязвимость системы `Data Scientist`  
  
#### 4.5. Безопасность данных   
  
- Нет ли нарушений GDPR и других законов `Data Scientist`  
  
#### 4.6. Издержки  
  
- Расчетные издержки на работу системы в месяц `Data Scientist`  
  
#### 4.5. Integration points  
  
- Описание взаимодействия между сервисами (методы API и др.) `Data Scientist`  
  
#### 4.6. Риски  
  
- Описание рисков и неопределенностей, которые стоит предусмотреть `Data Scientist`   
  
> ### Материалы для дополнительного погружения в тему  
> - [Шаблон ML System Design Doc [EN] от AWS](https://github.com/eugeneyan/ml-design-docs) и [статья](https://eugeneyan.com/writing/ml-design-docs/) с объяснением каждого раздела  
> - [Верхнеуровневый шаблон ML System Design Doc от Google](https://towardsdatascience.com/the-undeniable-importance-of-design-docs-to-data-scientists-421132561f3c) и [описание общих принципов его заполнения](https://towardsdatascience.com/understanding-design-docs-principles-for-achieving-data-scientists-53e6d5ad6f7e).
> - [ML Design Template](https://www.mle-interviews.com/ml-design-template) от ML Engineering Interviews  
> - Статья [Design Documents for ML Models](https://medium.com/people-ai-engineering/design-documents-for-ml-models-bbcd30402ff7) на Medium. Верхнеуровневые рекомендации по содержанию дизайн-документа и объяснение, зачем он вообще нужен  
> - [Краткий Canvas для ML-проекта от Made with ML](https://madewithml.com/courses/mlops/design/#timeline). Подходит для верхнеуровневого описания идеи, чтобы понять, имеет ли смысл идти дальше.  
