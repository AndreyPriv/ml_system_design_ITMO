# ML System Design Doc - [RU]
## Дизайн ML системы - Машинный перевод с русского на мансийский язык (MVP, Итерация 1)

*Шаблон ML System Design Doc от телеграм-канала [Reliable ML](https://t.me/reliable_ml)*   

- Рекомендации по процессу заполнения документа (workflow) - [здесь](https://github.com/IrinaGoloshchapova/ml_system_design_doc_ru/blob/main/ML_System_Design_Doc_Workflow.md).  
- Детальный доклад о том, что такое ML System Design Doc и о том, как, когда и зачем его составлять - [тут](https://www.youtube.com/watch?v=PW9TGNr1Vqk).
    
> ## Термины и пояснения
> - Итерация - это все работы, которые совершаются до старта очередного пилота  
> - БТ - бизнес-требования 
> - EDA - Exploratory Data Analysis - исследовательский анализ данных  
> - `Product Owner`,  `Data Scientist` - роли, которые заполняют соответствующие разделы 
> - В этом шаблоне роль `Data Scientist` совмещает в себе компетенции классического `Data Scientist` с упором на исследования и `ML Engineer` & `ML Ops` роли с акцентом на продуктивизацию моделей
> - Для вашей организации распределение ролей может быть уточнено в зависимости от операционной модели 

### 1. Цели и предпосылки 
#### 1.1. Зачем идем в разработку продукта?  

- Бизнес-цель
  
    Целью проекта является создание доступного и эффективного инструмента для машинного перевода с русского языка на мансийский и обратно с использованием современных технологий машинного обучения.

- Почему станет лучше, чем сейчас, от использования ML

    Мансийский язык, как и многие другие языки коренных народов, находится под угрозой исчезновения. Машинный перевод может сыграть важную роль в сохранении этого языка, улучшении доступности информации на нем и популяризации среди новых поколений. С помощью машинного перевода можно будет переводить различные образовательные материалы, литературу и другие ресурсы с русского на мансийский, что значительно расширит доступность информации для носителей языка и повысит интерес к изучению языка.

- Что будем считать успехом итерации с точки зрения бизнеса
  - Функциональность API:
    - API должно быть развернуто и доступно для работы через REST-запросы.
    - API предоставляет перевод текста с русского на мансийский и обратно.
  - Быстродействие API:
    - Среднее время отклика: Перевод одной строки текста (длиной до 100 символов) выполняется за менее чем 1 секунду в 95% случаев.
    - Гарантированное время отклика (SLA): Время ответа API не превышает 2 секунд даже при максимальной нагрузке.
  - BLEU (Bilingual Evaluation Understudy):
    - Целевой показатель для базовой модели составляет 20–30% для первых итераций.
    - Сравнение модели с репрезентативным тестовым набором из параллельных предложений.
  - Удовлетворенность пользователей (реальные отзывы):
    - Минимум 80% положительных отзывов от тестовых пользователей на этапе пилота.
  - Пользовательский опыт (UX):
    - Время загрузки веб-интерфейса: Меньше 2 секунд.
    - Интуитивно понятный интерфейс для работы с API и перевода текста.

#### 1.2. Бизнес-требования и ограничения  

- Краткое описание БТ и ссылки на детальные документы с бизнес-требованиями

    Веб-сервис должен предоставить интуитивно понятный интерфейс для пользователей, позволяя переводить текст в режиме онлайн с русского на мансийский и наоборот.
  
- Бизнес-ограничения
  - Ограниченный объем обучающих данных для мансийского языка.
  - Сроки на реализацию итерации: 3 месяца.
  - Ограниченный бюджет на инфраструктуру.
    
- Что мы ожидаем от конкретной итерации
  - Первая версия модели с базовым качеством перевода, оптимизированная под реальное использование.
  - Базовая версия пользовательского интерфейса (веб-сервис).
- Описание бизнес-процесса пилота, насколько это возможно - как именно мы будем использовать модель в существующем бизнес-процессе?

    Пользователи вводят текст на русском или мансийском в веб-интерфейсе и получают перевод на целевой язык. В пилоте используется базовая Seq2Seq модель, обученная на корпусе мансийского языка и развернутая через API.
  
- Что считаем успешным пилотом? Критерии успеха и возможные пути развития проекта
  - Веб-сервис успешно обрабатывает запросы в реальном времени.
  - BLEU-оценка для перевода соответствует запланированным метрикам.
  - Получены положительные отзывы от пользователей (минимум 80% удовлетворенности).

#### 1.3. Что входит в скоуп проекта/итерации, что не входит   

- На закрытие каких БТ подписываемся в данной итерации
  - Разработка и развертывание базовой модели машинного перевода для русского и мансийского языков.
  - Создание API для работы с переводчиком.
  - Подготовка минимального набора данных для обучения и тестирования модели.   
- Что не будет закрыто
  - Интеграция с внешними платформами.
  - Оптимизация модели для перевода длинных текстов.
- Описание результата с точки зрения качества кода и воспроизводимости решения
  Код будет полностью задокументирован и протестирован. Решение должно быть воспроизводимым для дальнейшего улучшения.  
- Описание планируемого технического долга (что оставляем для дальнейшей продуктивизации)
  - Оптимизация модели для работы с большими текстовыми массивами.
  - Добавление системы логирования запросов и их обработки.
  - Внедрение переводчика в популярные онлайн-переводчики.

#### 1.4. Предпосылки решения  

- Описание всех общих предпосылок решения, используемых в системе – с обоснованием от запроса бизнеса: какие блоки данных используем, горизонт прогноза, гранулярность модели, и др.
  - Данные: используем корпус параллельных текстов на русском и мансийском языках. Это могут быть литературные произведения, учебные материалы и официальные документы. Однако, для достижения необходимого объема данных, будут предприняты дополнительные шаги:
    - Предобработка текста. На этапе подготовки данные будут очищены от ошибок, некорректных символов, дубликатов и пустых строк. Также будет проведена токенизация текста (разбиение на слова и предложения) и нормализация (приведение текста к единому виду). Эти меры необходимы для повышения качества обучающего корпуса.
    - Дополнение корпуса. Планируется расширить корпус данных с помощью парсинга открытых источников, таких как электронные библиотеки, учебные материалы, государственные сайты и официальные документы. Автоматизированный сбор данных позволит дополнить корпус новыми текстовыми парами, соответствующими тематике проекта.
  - Модель: базируемся на Seq2Seq-модели из библиотеки transformers. Seq2Seq подход предоставляет удобную архитектуру для обучения как на больших, так и на малых объемах данных. Базовые Seq2Seq модели легко настраиваются, поддерживают дообучение на специфических языках и предоставляют хорошие результаты для пар языков с разной структурой. Он поддерживает использование предобученных моделей, что позволяет сократить потребность в данных. Для базовой версии выбирается уже предобученная модель, дообученная на собранном корпусе данных. 
  - Горизонт прогноза: Перевод отдельных предложений или коротких абзацев текста.
  - Гранулярность: Уровень перевода — предложение или абзац, ориентированный на точность синтаксического и семантического соответствия.

### 2. Методология `Data Scientist`     

#### 2.1. Постановка задачи  

- С технической точки зрения задача формулируется как:
  - Построение системы машинного перевода на основе Seq2Seq-модели.
  - Разработка и развертывание REST API для перевода текстов.
  - Построение пайплайна, включающего:
    - Предобработку данных.
    - Обучение модели на парных данных (русский-мансийский).
    - Постобработку результата перевода.

#### 2.2. Блок-схема решения  
- ![Блок-схема](diagram.png)
    - Этап 0: Получение корпуса переводов
      - Цель этапа – собрать и подготовить корпус текстов на русском и мансийском языках, чтобы обучить модель машинного перевода. Дополнительный парсинг данных из официальных источников, включая: литературные произведения (на обоих языках). учебные материалы (словари, пособия, справочники), официальные документы (юридические, государственные).
    - Этап 1: Подготовка данных
      - На этом этапе происходит обработка корпуса переводов для их последующего использования в обучении, например, удаление лишних символов, ошибок, пустых строк.
    - Этап 2: Обучение модели
      - Этап направлен на создание и настройку моделей машинного перевода. Обучение проводится на нескольких архитектурах для выбора наилучшего решения. Результаты промежуточного обучения каждой модели сравниваются по ключевым метрикам: BLEU. Выбирается модель с наилучшим качеством перевода. Выбранная модель дообучается на более редких и сложных примерах, чтобы улучшить качество перевода специфических конструкций.
    - Этап 3: Создание веб-сервиса
      - Цель этапа – разработать функциональный веб-сервис для использования обученной модели перевода: REST API и UI с последующим объединением в единый продукт.
    - Этап 4: Нагрузочное тестирование
      - На этом этапе проводится тестирование веб-сервиса под различными нагрузками. Проверяются сценарии: обработка большого числа запросов одновременно, работа с текстами разных объёмов (короткие, длинные),корректность перевода при нестандартных данных (например, смешении языков).
    - Этап 5: MVP (Минимально жизнеспособный продукт)
      - Заключительный этап, на котором создаётся функциональный продукт, готовый для тестового использования:

#### 2.3. Этапы решения задачи `Data Scientist`  
#### *Этап 0 - EDA*  

1. Цель анализа <br>
EDA проводится для оценки состава, объема и качества данных, а также для выявления потенциальных проблем, которые могут повлиять на обучение модели. Используемый датасет содержит параллельные тексты на русском и мансийском языках.
2. Описание данных
Датасет: overall_80K.csv:
   - Количество строк: 81146
   - Колонки:
     - Unnamed: 0 — служебный индекс (удален на этапе предобработки).
     - source — текст на русском языке.
     - target — текст на мансийском языке.

3. Предобработка данных:
   - Удаление строк с одинаковыми текстами.
   - Токенизация и очистка текста.
   - Для русского языка необходимо дальнейшее улучшение качества данных (например, удаление записей с низким качеством).
- [Оригинальный датасет](../notebooks/EDA/overall_80K.csv)
- [Предобработанный датасет](../notebooks/EDA/overall_80K_corrected.csv)
- [Ноутбук](../notebooks/EDA/correcting_dataset.ipynb)   

#### *Этап 1 - Подготовка данных*  
1. Данные и сущности, на которых будет обучаться  модель машинного обучения  
  
| Название данных  | Есть ли данные в компании (если да, название источника/витрин) | Требуемый ресурс для получения данных (какие роли нужны) | Проверено ли качество данных (да, нет) |
| ------------- | ------------- | ------------- | ------------- |
| Параллельные тексты на русском и мансийском | Да (корпус overall_80K)  | DE/DS | + |
| Данные, полученные с помощью скрейпинга  | Нет (собраны дополнительно)  | DE/DS	 | + |
| Слова и выражения из мансийского словаря | Нет (скрейпинг словаря)  | DE/DS	 | + |
 
2. Описание данных, состав, объем и качество
   - Первичный датасет:
     - Исходный объем: 81146 строк × 3 столбца (Unnamed: 0, source, target).
     - Обработанный объем: 79958 строк × 2 столбца (source, target).
   - Проблемы:
     - Удалены строки с одинаковыми текстами на русском и мансийском языках (source == target), которые не добавляют ценности для обучения. Это сократило объем данных, но повысило их релевантность.
     - В текстах на русском языке выявлены "шумные" слова (плохая разборчивость с помощью морфологического анализатора).
   - Дополнения к выборке:
     - Скрапинг словаря (Афанасьева К.В., Собянина С.А.):
       - Добавлены дополнительные пары слов (мансийский-русский).
       - Эти данные увеличили объем корпуса и охват тематик, представленных в тексте.
    - Скрапинг материалов:
      - Увеличили количество записей, ориентированных на сложные синтаксические конструкции.
        
3. Данные и сущности, на которых будет обучаться  модель машинного обучения
   - Объем данных:
     - Несмотря на все предпринятые меры (скрейпинг, дополнение из словарей), объем данных остается ограниченным. Это связано с малым количеством текстов на мансийском языке в открытых источниках.
     - Риск: Невозможность обеспечить высокое качество перевода из-за нехватки данных
   - Качество данных:
     - В первичном корпусе значительных проблем с качеством не выявлено. Однако тексты на русском языке иногда включают шум, что может повлиять на обучение модели.
   - Неравномерность распределения данных:
     - Возможно, определенные темы и лексические структуры представлены слабо. Это может привести к ухудшению качества перевода в специфических областях.

4. Описание процесса генерации данных
   - Источники данных:
     - Основной корпус: параллельные тексты (литература, официальные документы, учебные материалы).
     - Скрапинг: мансийско-русский словарь, доступные материалы из интернета.
   - Формат данных:
     - Данные хранятся в виде CSV файлов с двумя колонками (source, target), где source — текст на русском языке, а target — текст на мансийском языке.
   - Процесс генерации:
     - Скрапинг данных из доступных источников (например, словари, литература).
     - Предобработка текстов: очистка от пунктуации, токенизация, проверка на корректность словоформ.
     - Обогащение данных через аугментацию (перестановка слов, изменение словоформ для увеличения объема данных).
  - Регулярность процесса:
    - Однократный сбор данных для текущего этапа. Возможно, в будущем потребуется дополнительный сбор данных, если объем окажется недостаточным.
      
5. Решение проблемы нехватки данных
   - Использование техники Transfer Learning:
     - Обучение модели на предобученных языковых моделях (например, NLLB-200 или mBART), которые уже имеют базовые знания о других языках.
   - Требуемый объем данных:
     - Для достижения приемлемого качества BLEU на уровне 20-30% потребуется около 100–150 тысяч пар предложений. Однако текущий объем данных (~80 тыс.) является максимальным, который можно собрать в рамках данной итерации.
       
6. Конфиденциальность данных
   - В текущем корпусе конфиденциальная информация отсутствует (источники — общедоступные материалы и словари).
   - Проверять все будущие дополнения к корпусу на наличие персональных данных или конфиденциальной информации.

7. Необходимый результат этапа
   - Обновленный корпус данных (overall_80K_corrected.csv).
   - Оценка состава данных и качества
   - Подготовленный процесс регулярной обработки данных
       
#### *Этап 2 - Подготовка прогнозных моделей*  
1. Выбранные метрики:
   - BLEU (Bilingual Evaluation Understudy):
     - Используется для оценки качества перевода текста, сравнивая переведенный текст с эталонным.
     - BLEU хорошо подходит для измерения точности перевода, так как оценивает совпадение n-грамм (на уровне слов и фраз) между предсказанным и референсным переводами. Для нашей задачи это ключевой критерий качества.
   - ROUGE (Recall-Oriented Understudy for Gisting Evaluation):
     - Оценивает полноту перевода, сравнивая пересечение n-грамм с референсным текстом.
     - ROUGE полезен для проверки, насколько полон перевод, что особенно важно при работе с редкими языками, где каждое слово может нести критическое значение.
2. Выбранная функция потерь:
   - Cross-Entropy Loss:
     - Используется для Seq2Seq-моделей.
     - Позволяет оптимизировать вероятность предсказания правильной последовательности токенов. Хорошо работает для задач генерации текста.

3. Описание схемы ML-валидации
   - Модель:
     - 80% данных на обучение.
     - 10% данных на валидацию.
     - 10% данных на тестирование.
     - Убедиться, что редкие конструкции равномерно распределены между train/val/test.
     - Баланс между количеством данных для обучения и проверки качества. Учитываем ограниченность данных.

4. Описание структуры бейзлайна
   - Разделение данных:
     - Модель 1: mBART
     - Модель 2: NLLB-200
     - Модель 3: T-50
  - Предобработка:
    - Удаление пунктуации, токенизация, нормализация.
    - Замена редких слов <UNK> токеном.
    - Удаление дублирующихся или неинформативных строк.
  - Процесс моделирования:
    - Обучение бейзлайна (Seq2Seq) на корпусе.
    - Оценка BLEU и ROUGE на валидационном наборе.
    - Дообучение лучшей модели.

5. Стратегии дальнейшего развития решения
   - Оптимизация гиперпараметров:
     - Bayesian Optimization для выбора оптимального learning rate, batch size и других параметров.
   - Data Augmentation:
     - Перевод текста через третий язык (back-translation).
     - Перестановка предложений и добавление шумов.
     
6. Анализ и интерпретация работы модели
   - Оценка качества:
     - Использование BLEU для общих текстов и ручной проверки для редких слов.
     - Сравнение перевода модели с эталонными переводами.
   - Интерпретация ошибок:
     - Анализ ошибок, допущенных моделью (например, грамматические ошибки, неправильные окончания).
     - Выявление паттернов ошибок (частотность, категории слов).
   - Влияние дополнительных данных:
     - Проверка, как добавление новых данных (например, словарей) улучшает BLEU/ROUGE.

7. Риски данного этапа и способы их снижения <br>
| Риск   | Способ снижения |
| ------------- | ------------- |
| Плохое качество перевода из-за редких слов  | Использование подкорпуса словаря и POS-тегов, фокус на редкие слова. |
| Неправильное разбиение данных, что ведет к смещению модели  | Стратификация данных перед разбиением, проведение нескольких тестов на разных подвыборках. |
| Перегрузка модели при обучении | Мониторинг метрик валидации, использование ранней остановки (Early Stopping). |

8.Необходимый результат этапа
    - Дообученная лучшая по показателям Seq2Seq-модель, продемонстрировавшая базовые показатели BLEU (>20%).
    - Анализ ошибок и выявление зон для улучшения.
    - Обоснованный бейзлайн с репрезентативными метриками (BLEU, ROUGE).
    - Полностью задокументированный процесс обучения и валидации модели.






### 3. Подготовка пилота  
  
#### 3.1. Способ оценки пилота  
  
- Краткое описание предполагаемого дизайна и способа оценки пилота `Product Owner`, `Data Scientist` with `AB Group` 
  
#### 3.2. Что считаем успешным пилотом  
  
Формализованные в пилоте метрики оценки успешности `Product Owner`   
  
#### 3.3. Подготовка пилота  
  
- Что можем позволить себе, исходя из ожидаемых затрат на вычисления. Если исходно просчитать сложно, то описываем этап расчетов ожидаемой вычислительной сложности на эксперименте с бейзлайном. И предусматриваем уточнение параметров пилота и установку ограничений по вычислительной сложности моделей. `Data Scientist` 

### 4. Внедрение `для production систем, если требуется`    

> Заполнение раздела 4 требуется не для всех дизайн документов. В некоторых случаях результатом итерации может быть расчет каких-то значений, далее используемых в бизнес-процессе для пилота.  
  
#### 4.1. Архитектура решения   
  
- Блок схема и пояснения: сервисы, назначения, методы API `Data Scientist`  
  
#### 4.2. Описание инфраструктуры и масштабируемости 
  
- Какая инфраструктура выбрана и почему `Data Scientist` 
- Плюсы и минусы выбора `Data Scientist` 
- Почему финальный выбор лучше других альтернатив `Data Scientist` 
  
#### 4.3. Требования к работе системы  
  
- SLA, пропускная способность и задержка `Data Scientist`  
  
#### 4.4. Безопасность системы  
  
- Потенциальная уязвимость системы `Data Scientist`  
  
#### 4.5. Безопасность данных   
  
- Нет ли нарушений GDPR и других законов `Data Scientist`  
  
#### 4.6. Издержки  
  
- Расчетные издержки на работу системы в месяц `Data Scientist`  
  
#### 4.5. Integration points  
  
- Описание взаимодействия между сервисами (методы API и др.) `Data Scientist`  
  
#### 4.6. Риски  
  
- Описание рисков и неопределенностей, которые стоит предусмотреть `Data Scientist`   
  
> ### Материалы для дополнительного погружения в тему  
> - [Шаблон ML System Design Doc [EN] от AWS](https://github.com/eugeneyan/ml-design-docs) и [статья](https://eugeneyan.com/writing/ml-design-docs/) с объяснением каждого раздела  
> - [Верхнеуровневый шаблон ML System Design Doc от Google](https://towardsdatascience.com/the-undeniable-importance-of-design-docs-to-data-scientists-421132561f3c) и [описание общих принципов его заполнения](https://towardsdatascience.com/understanding-design-docs-principles-for-achieving-data-scientists-53e6d5ad6f7e).
> - [ML Design Template](https://www.mle-interviews.com/ml-design-template) от ML Engineering Interviews  
> - Статья [Design Documents for ML Models](https://medium.com/people-ai-engineering/design-documents-for-ml-models-bbcd30402ff7) на Medium. Верхнеуровневые рекомендации по содержанию дизайн-документа и объяснение, зачем он вообще нужен  
> - [Краткий Canvas для ML-проекта от Made with ML](https://madewithml.com/courses/mlops/design/#timeline). Подходит для верхнеуровневого описания идеи, чтобы понять, имеет ли смысл идти дальше.  
